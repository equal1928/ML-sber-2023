{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d73c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n",
    "# from keras_contrib.layers import CRF\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from keras_contrib.layers import CRF\n",
    "# from tensorflow_addons.layers import CRF\n",
    "from tf_crf_layer.loss import crf_loss\n",
    "from tf_crf_layer.metrics import crf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd16b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_wordsB.pkl', 'rb') as dict_words:\n",
    "    dict_words = pickle.load(dict_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be573f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_tegsB.pkl', 'rb') as dict_tegs:\n",
    "    dict_tegs = pickle.load(dict_tegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9481f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_token = len(dict_words)\n",
    "n_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tag = len(dict_tegs)\n",
    "n_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d45e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(s) for s in  data['text_ind'].tolist()])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_train_test_val(data):\n",
    "\n",
    "    #максимальная длина токена и тэга\n",
    "#     n_token = len(list(set(data['Word'].to_list())))\n",
    "#     n_tag = len(list(set(data['Tag'].to_list())))\n",
    "\n",
    "    #Pad tokens (X var)    \n",
    "    tokens = data['text_ind'].tolist()\n",
    "    maxlen = max([len(s) for s in  data['text_ind'].tolist()])\n",
    "#     maxlen = 100\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "\n",
    "    #Pad Tags (y var) и конвертируем в one hot encoding\n",
    "    tags = data['tag_ind'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= dict_tegs[\"o\"])\n",
    "    n_tags = len(dict_tegs)+1\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    #Split train, test and validation set\n",
    "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tags length:', len(train_tags),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(val_tokens),\n",
    "        '\\nval_tags:', len(val_tags),\n",
    "    )\n",
    "    \n",
    "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee032d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем состояния для воспроизводимости экспериментов\n",
    "from numpy.random import seed\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = n_token+1\n",
    "output_dim = 300\n",
    "input_length = max([len(s) for s in  data['text_ind'].tolist()])\n",
    "# input_length = 100\n",
    "n_tags = len(dict_tegs)+1\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f789e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # Слой Embedding\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Слой BILSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    #     model.add(Dropout(0.2))\n",
    "\n",
    "    # Слой LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    #     model.add(Dropout(0.2))\n",
    "\n",
    "    #     crf_layer = CRF(n_tags)\n",
    "    #     model.add(crf_layer)\n",
    "\n",
    "    # Слой timeDistributed Layer \n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
    "\n",
    "    # crf_layer = CRF(n_tags)\n",
    "    # model.add(crf_layer)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #Optimiser \n",
    "    adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    # model.compile(optimizer='adam', loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa48b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(train_tokens, np.array(train_tags), batch_size=64, verbose=1, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    for i in range(5):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=64, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bilstm_lstm = get_bilstm_lstm_model()\n",
    "plot_model(model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debec4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfa40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe369e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i])\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "test_pred = model.predict(X_test, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd330fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2648bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ed1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49beafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c351c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
